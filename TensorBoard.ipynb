{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4193,
     "status": "ok",
     "timestamp": 1545971418757,
     "user": {
      "displayName": "winston kim",
      "photoUrl": "",
      "userId": "05942964544969189760"
     },
     "user_tz": -480
    },
    "id": "zR7zohgoDRjh",
    "outputId": "fc62853d-f3bd-4539-f890-dcbdf7a0303b"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboardcolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6091,
     "status": "ok",
     "timestamp": 1545970812322,
     "user": {
      "displayName": "winston kim",
      "photoUrl": "",
      "userId": "05942964544969189760"
     },
     "user_tz": -480
    },
    "id": "_bf1Gm5tBsEH",
    "outputId": "db84feb9-369c-413f-aafa-882cd19eb904"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 훈려용 데이터 가져오기\n",
    "# 초기 상태에선 PIL（Python Imaging Library) 이미지 형식으로\n",
    "# Dataset를 만들어 버린다.\n",
    "# 따라서 transforms.ToTensor를 사용해 Tensor로 변환한다\n",
    "fashion_mnist_train = FashionMNIST(\"data\",\n",
    "    train=True, download=True,\n",
    "    transform=transforms.ToTensor())\n",
    "# 검증용 데이터 가져오기\n",
    "fashion_mnist_test = FashionMNIST(\"data\",\n",
    "    train=False, download=True,\n",
    "    transform=transforms.ToTensor())\n",
    "\n",
    "# 배치 크기가 128인 DataLoader를 각각 작성\n",
    "batch_size=128\n",
    "train_loader = DataLoader(fashion_mnist_train,\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(fashion_mnist_test,\n",
    "                          batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmv-7czQCwRE"
   },
   "outputs": [],
   "source": [
    "# (N, C, H, W)혀익의 Tensor를(N, C*H*W)로 늘리는 계층\n",
    "# 합성곱 출력을 MLP에 전달할 때 필요\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "\n",
    "# 5×5의 커널을 사용해서 처음에 32개, 다음에 64개의 채널 작성\n",
    "# BatchNorm2d는 이미지용 Batch Normalization\n",
    "# Dropout2d는 이미지용 Dropout\n",
    "# 마지막으로 FlattenLayer 적용\n",
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlattenLayer()\n",
    ")\n",
    "\n",
    "# 합성곱에 의해 최종적으로 이미지 크기가 어떤지를\n",
    "# 더미 데이터를 넣어서 확인한다\n",
    "\n",
    "test_input = torch.ones(1, 1, 28, 28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# 2층 MLP\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200, 10)\n",
    ")\n",
    "# 최종 CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0m85h757C5t3"
   },
   "outputs": [],
   "source": [
    "# 평가용 헬퍼 함수\n",
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # Dropout 및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # to 메서드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 클래스를 예측(리스트 2.1 참조)\n",
    "        # 여기선 forward（추론） 계산이 전부이므로 자동 미분에\n",
    "        # 필요한 처리는 off로 설정해서 불필요한 계산을 제한다\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    \n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "# 훈련용 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader,\n",
    "              optimizer_cls=optim.Adam,\n",
    "              loss_fn=nn.CrossEntropyLoss(),\n",
    "              n_iter=10, device=\"cpu\", writer=None):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련 모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "            total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도\n",
    "        train_acc.append(n_acc / n)\n",
    "\n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "            val_acc[-1], flush=True)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('train_loss', train_losses[-1], epoch)\n",
    "            writer.add_scalars('accuracy', {\n",
    "                \"train\": train_acc[-1],\n",
    "                \"validation\": val_acc[-1]\n",
    "            }, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 241438,
     "status": "ok",
     "timestamp": 1545972423379,
     "user": {
      "displayName": "winston kim",
      "photoUrl": "",
      "userId": "05942964544969189760"
     },
     "user_tz": -480
    },
    "id": "8CPs2pH8Dk2A",
    "outputId": "075a4a48-f93a-42b3-b4d2-49c188865041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 72.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.47804910995257205 0.8339833333333333 0.87909996509552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 73.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.32084448075192606 0.8825333333333333 0.8947999477386475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 73.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.28731478836673957 0.8957333333333334 0.9030999541282654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 73.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.2612953199407993 0.9028166666666667 0.9020999670028687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 69.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.24510507070674345 0.9091666666666667 0.9077999591827393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.23236430609901237 0.9139166666666667 0.9110999703407288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 75.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.2236799967721996 0.9195166666666666 0.9134999513626099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 75.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.20970991877918568 0.9221833333333334 0.905299961566925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 75.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.20374279684172228 0.9231833333333334 0.9120999574661255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.19618853819994336 0.9281166666666667 0.9185999631881714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.19131804545784098 0.9295333333333333 0.9160999655723572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.18693096431083658 0.9315166666666667 0.9182999730110168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 75.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.178357561564662 0.9342 0.920699954032898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.17567515066769132 0.9349833333333334 0.9165999889373779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.17265483311926708 0.9355166666666667 0.9182999730110168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.16599149120032278 0.9380333333333334 0.9214999675750732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.1589852001470251 0.9402833333333334 0.9188999533653259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.16009286854766372 0.9407166666666666 0.9222999811172485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 74.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.15526436990461287 0.9418166666666666 0.9208999872207642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 75.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.150135051092913 0.9435 0.9181999564170837\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# SummaryWriter 작성\n",
    "writer = SummaryWriter(\"data/cnn\")\n",
    "\n",
    "# 훈련 실행\n",
    "net.to(\"cuda:0\")\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\", writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.13.1 at http://ubuntu16:6006 (Press CTRL+C to quit)\n",
      "I0605 16:58:03.965746 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:03] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:04.536676 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:04] \"\u001b[37mGET /font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.062269 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /tf-interactive-inference-dashboard/editedexample.png HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.062673 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /tf-interactive-inference-dashboard/distance.png HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.063395 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /tf-interactive-inference-dashboard/explorecounterfactuals.png HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.065801 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /tf-interactive-inference-dashboard/pdplots.png HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.126975 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.127591 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.127790 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.128964 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.247395 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/tags HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.285689 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.287650 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.301756 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /font-roboto/d-6IYplOFocCacKzxwXSOJBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.303280 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.303981 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.309704 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.457075 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Fvalidation&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.457266 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Ftrain&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.457611 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=train_loss&run=.&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.486299 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/tags HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.652718 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Ftrain&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.653725 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=train_loss&run=.&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:05.656254 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:05] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Fvalidation&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.534538 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.535730 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.536140 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.536693 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.543472 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/plugin/scalars/tags HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.605794 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Fvalidation&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.606732 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Ftrain&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:16.607854 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:16] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=train_loss&run=.&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.295809 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.296777 139837818529536 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.298907 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.302080 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.320079 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/plugin/scalars/tags HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.372582 139837826922240 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Ftrain&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.376120 139837908952832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=accuracy&run=accuracy%2Fvalidation&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "I0605 16:58:35.379312 139837810136832 _internal.py:122] ::ffff:127.0.0.1 - - [05/Jun/2019 16:58:35] \"\u001b[37mGET /data/plugin/scalars/scalars?tag=train_loss&run=.&experiment= HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir data/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "appendix1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

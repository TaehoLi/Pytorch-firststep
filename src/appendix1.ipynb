{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"appendix1.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"nl-QtRD7CKqE","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install http://download.pytorch.org/whl/cu90/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n","!pip install torchvision\n","!pip install tqdm\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zR7zohgoDRjh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"fc62853d-f3bd-4539-f890-dcbdf7a0303b","executionInfo":{"status":"ok","timestamp":1545971418757,"user_tz":-480,"elapsed":4193,"user":{"displayName":"winston kim","photoUrl":"","userId":"05942964544969189760"}}},"cell_type":"code","source":["!pip install tensorboardcolab"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"}]},{"metadata":{"id":"rip7B7IADznm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"0820f8a0-f438-498b-e257-843295e50743","executionInfo":{"status":"ok","timestamp":1545971391604,"user_tz":-480,"elapsed":247947,"user":{"displayName":"winston kim","photoUrl":"","userId":"05942964544969189760"}}},"cell_type":"code","source":["!tensorboard --logdir /content/cnn"],"execution_count":12,"outputs":[{"output_type":"stream","text":["TensorBoard 1.12.1 at http://29bfae16dbc9:6006 (Press CTRL+C to quit)\n","^C\n"],"name":"stdout"}]},{"metadata":{"id":"_bf1Gm5tBsEH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":145},"outputId":"db84feb9-369c-413f-aafa-882cd19eb904","executionInfo":{"status":"ok","timestamp":1545970812322,"user_tz":-480,"elapsed":6091,"user":{"displayName":"winston kim","photoUrl":"","userId":"05942964544969189760"}}},"cell_type":"code","source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n","import tqdm\n","\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms\n","\n","# 훈려용 데이터 가져오기\n","# 초기 상태에선 PIL（Python Imaging Library) 이미지 형식으로\n","# Dataset를 만들어 버린다.\n","# 따라서 transforms.ToTensor를 사용해 Tensor로 변환한다\n","fashion_mnist_train = FashionMNIST(\"/content/FashionMNIST\",\n","    train=True, download=True,\n","    transform=transforms.ToTensor())\n","# 검증용 데이터 가져오기\n","fashion_mnist_test = FashionMNIST(\"/content/FashionMNIST\",\n","    train=False, download=True,\n","    transform=transforms.ToTensor())\n","\n","# 배치 크기가 128인 DataLoader를 각각 작성\n","batch_size=128\n","train_loader = DataLoader(fashion_mnist_train,\n","                          batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(fashion_mnist_test,\n","                          batch_size=batch_size, shuffle=False)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"metadata":{"id":"dmv-7czQCwRE","colab_type":"code","colab":{}},"cell_type":"code","source":["# (N, C, H, W)혀익의 Tensor를(N, C*H*W)로 늘리는 계층\n","# 합성곱 출력을 MLP에 전달할 때 필요\n","class FlattenLayer(nn.Module):\n","    def forward(self, x):\n","        sizes = x.size()\n","        return x.view(sizes[0], -1)\n","\n","# 5×5의 커널을 사용해서 처음에 32개, 다음에 64개의 채널 작성\n","# BatchNorm2d는 이미지용 Batch Normalization\n","# Dropout2d는 이미지용 Dropout\n","# 마지막으로 FlattenLayer 적용\n","conv_net = nn.Sequential(\n","    nn.Conv2d(1, 32, 5),\n","    nn.MaxPool2d(2),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(32),\n","    nn.Dropout2d(0.25),\n","    nn.Conv2d(32, 64, 5),\n","    nn.MaxPool2d(2),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(64),\n","    nn.Dropout2d(0.25),\n","    FlattenLayer()\n",")\n","\n","# 합성곱에 의해 최종적으로 이미지 크기가 어떤지를\n","# 더미 데이터를 넣어서 확인한다\n","\n","test_input = torch.ones(1, 1, 28, 28)\n","conv_output_size = conv_net(test_input).size()[-1]\n","\n","# 2층 MLP\n","mlp = nn.Sequential(\n","    nn.Linear(conv_output_size, 200),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(200),\n","    nn.Dropout(0.25),\n","    nn.Linear(200, 10)\n",")\n","# 최종 CNN\n","net = nn.Sequential(\n","    conv_net,\n","    mlp\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0m85h757C5t3","colab_type":"code","colab":{}},"cell_type":"code","source":["# 평가용 헬퍼 함수\n","def eval_net(net, data_loader, device=\"cpu\"):\n","    # Dropout 및 BatchNorm을 무효화\n","    net.eval()\n","    ys = []\n","    ypreds = []\n","    for x, y in data_loader:\n","        # to 메서드로 계산을 실행할 디바이스로 전송\n","        x = x.to(device)\n","        y = y.to(device)\n","        # 확률이 가장 큰 클래스를 예측(리스트 2.1 참조)\n","        # 여기선 forward（추론） 계산이 전부이므로 자동 미분에\n","        # 필요한 처리는 off로 설정해서 불필요한 계산을 제한다\n","        with torch.no_grad():\n","            _, y_pred = net(x).max(1)\n","        ys.append(y)\n","        ypreds.append(y_pred)\n","    \n","    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n","    ys = torch.cat(ys)\n","    ypreds = torch.cat(ypreds)\n","    # 예측 정확도 계산\n","    acc = (ys == ypreds).float().sum() / len(ys)\n","    return acc.item()\n","\n","# 훈련용 헬퍼 함수\n","def train_net(net, train_loader, test_loader,\n","              optimizer_cls=optim.Adam,\n","              loss_fn=nn.CrossEntropyLoss(),\n","              n_iter=10, device=\"cpu\", writer=None):\n","    train_losses = []\n","    train_acc = []\n","    val_acc = []\n","    optimizer = optimizer_cls(net.parameters())\n","    for epoch in range(n_iter):\n","        running_loss = 0.0\n","        # 신경망을 훈련 모드로 설정\n","        net.train()\n","        n = 0\n","        n_acc = 0\n","        # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n","        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n","            total=len(train_loader)):\n","            xx = xx.to(device)\n","            yy = yy.to(device)\n","            h = net(xx)\n","            loss = loss_fn(h, yy)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            n += len(xx)\n","            _, y_pred = h.max(1)\n","            n_acc += (yy == y_pred).float().sum().item()\n","        train_losses.append(running_loss / i)\n","        # 훈련 데이터의 예측 정확도\n","        train_acc.append(n_acc / n)\n","\n","        # 검증 데이터의 예측 정확도\n","        val_acc.append(eval_net(net, test_loader, device))\n","        # epoch의 결과 표시\n","        print(epoch, train_losses[-1], train_acc[-1],\n","            val_acc[-1], flush=True)\n","        if writer is not None:\n","            writer.add_scalar('train_loss', train_losses[-1], epoch)\n","            writer.add_scalars('accuracy', {\n","                \"train\": train_acc[-1],\n","                \"validation\": val_acc[-1]\n","            }, epoch)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8CPs2pH8Dk2A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":737},"outputId":"075a4a48-f93a-42b3-b4d2-49c188865041","executionInfo":{"status":"ok","timestamp":1545972423379,"user_tz":-480,"elapsed":241438,"user":{"displayName":"winston kim","photoUrl":"","userId":"05942964544969189760"}}},"cell_type":"code","source":["from tensorboardX import SummaryWriter\n","\n","# SummaryWriter 작성\n","writer = SummaryWriter(\"/content/cnn\")\n","\n","# 훈련 실행\n","net.to(\"cuda:0\")\n","train_net(net, train_loader, test_loader, n_iter=20, device=\"cuda:0\", writer=writer)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.3256517777967657 0.88215 0.8935999870300293\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 42.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["1 0.287139225910362 0.8945833333333333 0.8965999484062195\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["2 0.2639670108054948 0.90225 0.8986999988555908\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["3 0.2471425553672334 0.9085 0.9088000059127808\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.35it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["4 0.2335608467204958 0.9131166666666667 0.9110999703407288\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["5 0.22311063185652608 0.91775 0.9098999500274658\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 44.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["6 0.2134799955205785 0.9218 0.915399968624115\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 42.73it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["7 0.20866159478632304 0.9219166666666667 0.9124999642372131\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["8 0.19825509637912625 0.9256166666666666 0.9157999753952026\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 42.81it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["9 0.1930915255768177 0.92745 0.915399968624115\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 43.26it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["10 0.18974440592603806 0.92835 0.9005999565124512\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 42.43it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["11 0.1837276028485125 0.9309666666666667 0.9199000000953674\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 43.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["12 0.1804003050375698 0.9329333333333333 0.9167999625205994\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 42.74it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["13 0.17374094176050434 0.9346 0.918999969959259\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:10<00:00, 42.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["14 0.16848618094610351 0.9369 0.920799970626831\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 43.66it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["15 0.16498865706957558 0.9381833333333334 0.9203999638557434\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 42.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["16 0.16173298138743028 0.9387666666666666 0.920199990272522\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 42.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["17 0.15761582151405576 0.94055 0.9218999743461609\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 42.63it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["18 0.15415703812534484 0.9415 0.9212999939918518\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 469/469 [00:11<00:00, 42.54it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["19 0.15295407954507914 0.9423333333333334 0.9168999791145325\n"],"name":"stdout"}]}]}